---
id: comp-20260205-121500-sk2l
depthUsed: comprehensive
timestamp: 2026-02-05T12:15:00Z
executed: false
originalPrompt: "as a claude-code-specialist agent, analyze all agents in claude/agents to identify potential skills that can be extracted from agents to make them more efficient"
---

# Improved Prompt

As a claude-code-specialist agent, audit every agent definition in `claude/agents/*.md`
to identify reusable behaviors that should be extracted into standalone skills.

## Architecture Context

This project has three distinct concepts:

- **Agents** (`claude/agents/<name>.md`): Role definitions used by the workflow-orchestrator
  during swarm runs (`/orchestrate`). Each agent has reads, writes, rules, and a process.
  Agents are spawned as `general-purpose` subagents by the orchestrator, tier by tier.

- **Skills** (`.claude/skills/<name>/SKILL.md` + optional `references/` folder):
  Reusable knowledge and capability modules that enhance Claude's behavior.
  A skill is a self-contained folder with a `SKILL.md` (core knowledge) and optional
  reference files. Skills are passive — they provide expertise, not workflows.

- **Commands** (`.claude/commands/<namespace>/<action>.md`):
  User-invokable slash commands (e.g., `/interface-design:init`). Commands define
  workflows and may reference skills for domain knowledge.

**Key distinction**: A skill is expertise/knowledge that enhances behavior.
A command is a workflow a user triggers. An agent is a role the orchestrator assigns.
The analysis should identify agent behaviors that could become **skills** (reusable
knowledge modules), **commands** (user-triggered workflows), or **both** (a skill
providing the knowledge + a command providing the entry point).

## Existing Skills and Commands (do not duplicate)

Already exist as skills:
- `interface-design` — Interface design craft and principles (`.claude/skills/interface-design/`)
- `frontend-design` — Frontend aesthetics and UI code generation (`.claude/skills/frontend-design/`)

Already exist as commands:
- `/interface-design:init`, `/interface-design:audit`, `/interface-design:extract`, `/interface-design:status`
- `/clavix:*` (improve, implement, prd, plan, refine, review, start, summarize, verify, archive)

## What to Analyze

Read each agent file in `claude/agents/` and identify behaviors that:
1. Are invoked independently of the full swarm orchestration (`/orchestrate`)
2. Could be triggered by a user directly — not only via the orchestrator
3. Contain self-contained domain knowledge or process logic
4. Are duplicated or nearly duplicated across multiple agents
5. Would benefit from having reusable reference material (like the interface-design skill has)

## Output Format

For each extraction candidate, provide:

| Field | Description |
|-------|-------------|
| Source agent(s) | Which agent(s) contain this behavior |
| Extract as | `skill`, `command`, or `skill + command` |
| Proposed name | Name following existing conventions (e.g., `spec-validation` for a skill, `/spec:validate` for a command) |
| What it does | One-sentence description |
| Why extract it | What reuse, efficiency, or standalone value this enables |
| SKILL.md sketch | For skills: 2-3 bullet points of what the SKILL.md would contain |
| Standalone? | Can it run without other agents? (Yes / Partial / No) |

## Scope

- Only analyze files in `claude/agents/`
- Do not modify any files — this is a read-only analysis
- Do not propose extractions that duplicate existing skills or commands listed above
- Focus on behaviors users would realistically invoke outside of `/orchestrate`
- Consider whether the extraction reduces agent complexity (lighter agents = faster swarm runs)

## Deliverable

A single analysis report with:
1. Summary of findings (how many candidates, by type)
2. Extraction candidates ordered by impact (highest value first)
3. A brief note on which agents become simpler after extraction

## Quality Scores
- **Clarity**: 90%
- **Efficiency**: 80%
- **Structure**: 90%
- **Completeness**: 85%
- **Actionability**: 85%
- **Specificity**: 85%
- **Overall**: 86% (good)

## Original Prompt
```
as a claude-code-specialist agent, analyze all agents in claude/agents to identify potential skills that can be extracted from agents to make them more efficient
```

## Alternative Approaches

**1. Agent-first audit**
Walk through each agent sequentially, listing what could be extracted from each. Best for: comprehensive coverage, easy to verify completeness.

**2. Pattern-first audit**
Look for cross-cutting patterns first (e.g., "spec validation appears in 4 agents"), then propose consolidated extractions. Best for: finding the highest-impact extractions that reduce duplication.

**3. User-journey-first audit**
Start from user workflows ("what would a user want to do outside /orchestrate?") and trace back to which agent behaviors support those workflows. Best for: ensuring extractions are actually useful standalone.

## Validation Checklist

After running this analysis, verify:
- [ ] Every agent in `claude/agents/` was analyzed
- [ ] No proposed extraction duplicates an existing skill or command
- [ ] Each "skill" extraction includes what SKILL.md would contain
- [ ] Each "command" extraction follows the naming convention (`/namespace:action`)
- [ ] Standalone rating is justified (not just "Yes" without explanation)
- [ ] At least one candidate is a `skill + command` pair (likely exists given the pattern)

## Edge Cases

- Agents whose entire purpose is orchestration-only (e.g., workflow-orchestrator, context-manager) — may have zero extractable behaviors
- Behaviors that look standalone but actually depend on artifacts from prior tiers
- Skills that would be useful but too thin to justify a separate folder (might just be a command)
