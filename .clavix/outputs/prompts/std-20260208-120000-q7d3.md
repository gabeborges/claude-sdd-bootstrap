---
id: std-20260208-120000-q7d3
depthUsed: standard
timestamp: 2026-02-08T12:00:00Z
executed: true
originalPrompt: "create an agent that is capable of analyzing product requirements, specs, and development docs and compare its quality"
---

# Improved Prompt

Objective: Build a document quality analysis agent that ingests product requirements (PRDs), technical specs, and development documentation, then scores each document against a defined quality rubric and produces a comparative quality report.

Context:
- This agent will be used within an SDD (Spec-Driven Development) workflow
- Documents live in `.ops/build/` directories as markdown/YAML files
- The agent should work as a Claude Code slash command or callable module

Input:
- One or more documents (PRD, spec, system-design YAML, tasks YAML)
- A quality rubric defining scoring dimensions (or use sensible defaults)

Analysis Dimensions (per document):
- Completeness: Are all expected sections present? Are there gaps?
- Clarity: Is the language unambiguous? Are requirements testable?
- Consistency: Do documents align with each other (e.g., spec matches PRD)?
- Traceability: Can each requirement be traced from PRD → spec → tasks?
- Actionability: Could a developer implement directly from this document?
- Specificity: Are there concrete details (versions, endpoints, schemas)?

Output:
- Per-document quality scorecard (dimensions scored 0-100%)
- Cross-document comparison matrix showing relative quality
- Gap analysis: what's missing or misaligned between documents
- Prioritized list of improvements for lowest-scoring areas

Technical Constraints:
- Use the existing project stack (Next.js, Supabase, TypeScript)
- Agent should be invocable via CLI or slash command
- Output as structured markdown saved to `.clavix/outputs/`

Success Criteria:
- Agent correctly identifies missing sections in incomplete documents
- Scores are consistent across multiple runs on the same input
- Cross-document comparison catches misalignment between PRD and spec
- Output is actionable — a human can fix issues based on the report

## Quality Scores
- **Clarity**: 45%
- **Efficiency**: 70%
- **Structure**: 60%
- **Completeness**: 30%
- **Actionability**: 35%
- **Specificity**: 25%
- **Overall**: 40% (needs-improvement)

## Original Prompt
```
create an agent that is capable of analyzing product requirements, specs, and development docs and compare its quality
```
